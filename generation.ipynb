{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhjTVBAwtYJd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pretty_midi\n",
    "from mido import Message, MidiFile, MidiTrack\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch.distributions\n",
    "import sparsemax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 116,
     "status": "aborted",
     "timestamp": 1652963745534,
     "user": {
      "displayName": "Sophia Hager",
      "userId": "07903191433304959107"
     },
     "user_tz": 240
    },
    "id": "f1ie7zGkh0sO"
   },
   "outputs": [],
   "source": [
    "data = torch.load(\"test_tempo.csv\")\n",
    "torch.manual_seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 117,
     "status": "aborted",
     "timestamp": 1652963745535,
     "user": {
      "displayName": "Sophia Hager",
      "userId": "07903191433304959107"
     },
     "user_tz": 240
    },
    "id": "mmq47OqZqDa_"
   },
   "outputs": [],
   "source": [
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 237,
     "status": "aborted",
     "timestamp": 1652963745655,
     "user": {
      "displayName": "Sophia Hager",
      "userId": "07903191433304959107"
     },
     "user_tz": 240
    },
    "id": "QghsXxPCngY8"
   },
   "outputs": [],
   "source": [
    "def get_chroma(roll, length):\n",
    "    chroma_matrix = torch.zeros((roll.size()[0],12))\n",
    "    for note in range(0, 12):\n",
    "        chroma_matrix[:, note] = torch.sum(roll[:, note::12], axis=1)\n",
    "    return chroma_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 238,
     "status": "aborted",
     "timestamp": 1652963745656,
     "user": {
      "displayName": "Sophia Hager",
      "userId": "07903191433304959107"
     },
     "user_tz": 240
    },
    "id": "TL98RMlOPkFA"
   },
   "outputs": [],
   "source": [
    "def batch_SSM(seq, batch_size):\n",
    "  SSMs = []\n",
    "  for i in range(0, batch_size):\n",
    "    SSMs.append(SSM(seq[:,i, :]))\n",
    "  return torch.vstack(SSMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 126,
     "status": "aborted",
     "timestamp": 1652963745656,
     "user": {
      "displayName": "Sophia Hager",
      "userId": "07903191433304959107"
     },
     "user_tz": 240
    },
    "id": "kbVFABahqRyr"
   },
   "outputs": [],
   "source": [
    "def SSM(sequence):\n",
    "  #tensor will be in form length, hidden_size (128)\n",
    "  cos = nn.CosineSimilarity(dim=1)\n",
    "  chrom = get_chroma(sequence, sequence.size()[0])\n",
    "  len = chrom.size()[0]\n",
    "  SSM=torch.zeros((len, len))\n",
    "  for i in range(0, len):\n",
    "    SSM[i] = cos(chrom[i].view(1, -1),chrom)\n",
    "  return (SSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 125,
     "status": "aborted",
     "timestamp": 1652963745656,
     "user": {
      "displayName": "Sophia Hager",
      "userId": "07903191433304959107"
     },
     "user_tz": 240
    },
    "id": "zWRL4AHyhqJo"
   },
   "outputs": [],
   "source": [
    "def make_batches(batch_size, data):\n",
    "  random.shuffle(data)\n",
    "  batches = []\n",
    "  num_batches = len(data)//batch_size\n",
    "  for i in range(0, num_batches):\n",
    "    batch = torch.cat(list(np.array(data)[i*batch_size: (i+1)*(batch_size)][:, 0])).view(batch_size, 400, 128)\n",
    "    batches.append(batch)\n",
    "  return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 125,
     "status": "aborted",
     "timestamp": 1652963745656,
     "user": {
      "displayName": "Sophia Hager",
      "userId": "07903191433304959107"
     },
     "user_tz": 240
    },
    "id": "iuKD5iNkyChL"
   },
   "outputs": [],
   "source": [
    "class music_generator(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(output_size, hidden_size, num_layers=1, bidirectional=True)\n",
    "        self.attention = nn.Linear(2, 1)\n",
    "        self.softmax = sparsemax.Sparsemax(dim=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, input, hidden, batch, sequence_length, ssm):\n",
    "        output, hidden = self.lstm(input.to(\"cuda:0\").float(), (hidden[0].to(\"cuda:0\").float(), hidden[1].to(\"cuda:0\").float()))\n",
    "        output_1 = output.to('cpu')[-5:, :,:]\n",
    "        new_output = output_1.view(5, batch, 2, 128)\n",
    "        avg_output = torch.sum(new_output, 2)\n",
    "        hidden_1_0 = hidden[0].to('cpu')\n",
    "        hidden_1_1= hidden[1].to('cpu')\n",
    "\n",
    "        \n",
    "\n",
    "        seqs = []\n",
    "        for l in range(0,5):\n",
    "          index = input.shape[0]+l\n",
    "          weights = self.softmax(ssm[range(index, ssm.shape[0], ssm.shape[1]), :index])\n",
    "          if l!=0:\n",
    "            input_and_gen = torch.vstack((input[:,:,:], torch.vstack((seqs))))\n",
    "          else:\n",
    "            input_and_gen = input[:,:,:]\n",
    "          weighted = (input_and_gen.T*weights).T\n",
    "          weight_vec = (torch.sum(weighted, axis=0))\n",
    "          pt2 = torch.hstack((weight_vec.unsqueeze(1), avg_output[l, : ,:].unsqueeze(1))).transpose(1,2)\n",
    "          attentioned = self.attention(pt2.float().to(\"cuda:0\")).to('cpu').permute(2,0,1)\n",
    "          seqs.append(attentioned)\n",
    "        newoutput = torch.vstack(seqs)\n",
    "\n",
    "        del output\n",
    "        del output_1\n",
    "        del ssm\n",
    "        del weights\n",
    "        del seqs\n",
    "        del hidden\n",
    "        del pt2\n",
    "        del attentioned\n",
    "        del input\n",
    "\n",
    "\n",
    "        return newoutput.double(), (hidden_1_0,hidden_1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 126,
     "status": "aborted",
     "timestamp": 1652963745657,
     "user": {
      "displayName": "Sophia Hager",
      "userId": "07903191433304959107"
     },
     "user_tz": 240
    },
    "id": "uSOP8KCNvHIb"
   },
   "outputs": [],
   "source": [
    "att_mod = torch.load(\"trained/best_model/attention_model.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 126,
     "status": "aborted",
     "timestamp": 1652963745657,
     "user": {
      "displayName": "Sophia Hager",
      "userId": "07903191433304959107"
     },
     "user_tz": 240
    },
    "id": "w0luDdramUyB"
   },
   "outputs": [],
   "source": [
    "def topk_sample_one(sequence, k):\n",
    "  #takes in size sequence length, batch size, values\n",
    "  softmax = sparsemax.Sparsemax(dim=2)\n",
    "  vals, indices = torch.topk(sequence[:, :, 20:108],k)\n",
    "  indices+=20\n",
    "  seq = torch.distributions.Categorical(softmax(vals.float()))\n",
    "  samples = seq.sample()\n",
    "  onehot = F.one_hot(torch.gather(indices, -1, samples.unsqueeze(-1)), num_classes = sequence.shape[2]).squeeze(dim=2)\n",
    "  return(onehot)\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 126,
     "status": "aborted",
     "timestamp": 1652963745657,
     "user": {
      "displayName": "Sophia Hager",
      "userId": "07903191433304959107"
     },
     "user_tz": 240
    },
    "id": "86DYqbCtrpqs"
   },
   "outputs": [],
   "source": [
    "def topk_batch_sample(sequence, k):\n",
    "  for i in range(0, 3):\n",
    "    new= topk_sample_one(sequence, k)\n",
    "    if i ==0:\n",
    "      sum = new\n",
    "    else:\n",
    "      sum+=new\n",
    "  return(torch.where(sum>0, 1, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 125,
     "status": "aborted",
     "timestamp": 1652963745657,
     "user": {
      "displayName": "Sophia Hager",
      "userId": "07903191433304959107"
     },
     "user_tz": 240
    },
    "id": "dOFR2z-30Cmb"
   },
   "outputs": [],
   "source": [
    "def generate(generator, initial_vectors, batch_size, length , hidden_shape, batched_ssm):\n",
    "  hidden = (torch.randn(2, 1, hidden_shape)).float()\n",
    "  generator.eval()\n",
    "  sequence = initial_vectors.transpose(0,1)\n",
    "  hidden = (hidden, hidden)\n",
    "  for i in range(0, length,5):\n",
    "    seq_length = sequence.size()[0]\n",
    "    with torch.no_grad():\n",
    "      output, hidden = generator.forward(sequence.float(), hidden, batch_size, seq_length, batched_ssm)\n",
    "      next_element = topk_batch_sample(output[-5:, :,:], 5)\n",
    "    sequence = torch.vstack((sequence, next_element.to(\"cpu\")))\n",
    "  return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 125,
     "status": "aborted",
     "timestamp": 1652963745657,
     "user": {
      "displayName": "Sophia Hager",
      "userId": "07903191433304959107"
     },
     "user_tz": 240
    },
    "id": "aJSNH2jRPw0V"
   },
   "outputs": [],
   "source": [
    "index = 45\n",
    "first_vec = data[index][0].unsqueeze(0)[:,0:10,:]\n",
    "print(first_vec.shape)\n",
    "new_gen_att = generate(att_mod, first_vec, 1, 390, 128, SSM(data[index][0]))\n",
    "plt.imshow(SSM(new_gen_att.squeeze()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 125,
     "status": "aborted",
     "timestamp": 1652963745657,
     "user": {
      "displayName": "Sophia Hager",
      "userId": "07903191433304959107"
     },
     "user_tz": 240
    },
    "id": "hxhjd4ijzH6-"
   },
   "outputs": [],
   "source": [
    "plt.imshow(SSM(data[index][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "aborted",
     "timestamp": 1652963745658,
     "user": {
      "displayName": "Sophia Hager",
      "userId": "07903191433304959107"
     },
     "user_tz": 240
    },
    "id": "luEz48jIyY1U"
   },
   "outputs": [],
   "source": [
    "plt.imshow(new_gen_att.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1652963745658,
     "user": {
      "displayName": "Sophia Hager",
      "userId": "07903191433304959107"
     },
     "user_tz": 240
    },
    "id": "5jemNprz1mB2"
   },
   "outputs": [],
   "source": [
    "def stop_note(note, time):\n",
    "    return Message('note_off', note = note,\n",
    "                   velocity = 0, time = time)\n",
    "\n",
    "def start_note(note, time):\n",
    "    return Message('note_on', note = note,\n",
    "                   velocity = 120, time = time)\n",
    "\n",
    "def roll_to_track(roll, tempo):\n",
    "    delta = 0\n",
    "\n",
    "    \n",
    "    # MIDI note for first column.\n",
    "    midi_base = 0\n",
    "    notes = [0] * len(roll[0])\n",
    "    for row in roll:\n",
    "        for i, col in enumerate(row):\n",
    "            note = i\n",
    "            if col>notes[i] and col!=0: \n",
    "                if notes[i]!=0:\n",
    "                    yield stop_note(note, delta)\n",
    "                    delta = 0\n",
    "                yield start_note(i, delta)\n",
    "                delta = 0\n",
    "                notes[i] = note\n",
    "            elif col == 0:\n",
    "                if notes[i]!=0:\n",
    "                    # Stop the ringing note\n",
    "                    yield stop_note(note, delta)\n",
    "                    delta = 0\n",
    "                notes[i] = 0\n",
    "        # ms per row\n",
    "        delta += int(np.round((1/(tempo/60))*1000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "aborted",
     "timestamp": 1652963745658,
     "user": {
      "displayName": "Sophia Hager",
      "userId": "07903191433304959107"
     },
     "user_tz": 240
    },
    "id": "hMlI54ma1nUt"
   },
   "outputs": [],
   "source": [
    "new_roll_final = np.vstack((new_gen_att.squeeze(), np.zeros(128)))\n",
    "midi = MidiFile(type = 1)\n",
    "midi.tracks.append(MidiTrack(roll_to_track(new_roll_final, data[index][1])))\n",
    "midi.save('blank.midi')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPwrcoyRMNEf3B52pEvfxGj",
   "collapsed_sections": [],
   "mount_file_id": "1mkRxlXNoW8JWcTdjhvJncio8eZy8_WGP",
   "name": "generation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

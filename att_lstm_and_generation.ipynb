{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thFK9gwfldz1"
   },
   "source": [
    "## Import Things so the Code Runs\n",
    "(Adjust your drive path!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd3K0avvtOAX",
    "outputId": "0f77bccb-36a4-4861-b619-80b70e971c3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pretty_midi in /opt/anaconda3/envs/csc294/lib/python3.8/site-packages (0.2.9)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/csc294/lib/python3.8/site-packages (from pretty_midi) (1.15.0)\n",
      "Requirement already satisfied: mido>=1.1.16 in /opt/anaconda3/envs/csc294/lib/python3.8/site-packages (from pretty_midi) (1.2.10)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /opt/anaconda3/envs/csc294/lib/python3.8/site-packages (from pretty_midi) (1.19.2)\n",
      "Requirement already satisfied: sparsemax in /opt/anaconda3/envs/csc294/lib/python3.8/site-packages (0.1.9)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/csc294/lib/python3.8/site-packages (from sparsemax) (1.13.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/anaconda3/envs/csc294/lib/python3.8/site-packages (from torch->sparsemax) (4.4.0)\n"
     ]
    }
   ],
   "source": [
    "drive = False  # False = Local\n",
    "if drive:\n",
    "    !pip install pretty_midi\n",
    "    !pip install -U sparsemax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UhjTVBAwtYJd",
    "outputId": "7eb6026e-784a-435d-8bf5-2d5a30cb821d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pretty_midi\n",
    "#this package is used to write it back into music.\n",
    "from mido import Message, MidiFile, MidiTrack\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch.distributions\n",
    "import sparsemax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if drive:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    my_drive_path = '/content/drive/MyDrive/2022_Special_Studies_Hablutzel/ModelCopies/'\n",
    "else: # local\n",
    "    my_drive_path = \"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fwoOduJlbgC"
   },
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "iuKD5iNkyChL"
   },
   "outputs": [],
   "source": [
    "#this is the model\n",
    "class music_generator(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size  # 128\n",
    "        # output_size is num expected features (128)\n",
    "        self.lstm = nn.LSTM(output_size, hidden_size, num_layers=1, bidirectional=False)\n",
    "        self.attention = nn.Linear(2, 1)\n",
    "        self.softmax = sparsemax.Sparsemax(dim=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.hidden = None\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "      # set hidden state to zeros after each batch #\n",
    "      hidden = (torch.zeros(1, batch_size, self.hidden_size))  # [layers, batch_size, hidden_size/features]\n",
    "      hidden = (hidden, hidden)  # hidden_state, cell_state\n",
    "      return hidden\n",
    "\n",
    "    def forward(self, input, batch_size, ssm):\n",
    "        # look at tensor things - view vs. reshape vs. permute, and unsqueeze and squeeze\n",
    "        # try looking at the LSTM equations\n",
    "        # .to('cpu')  # returns a copy of the tensor in CPU memory\n",
    "        # .to('cuda:0')  # returns copu in CUDA memory, 0 indicates first GPU device\n",
    "        # https://pytorch.org/docs/stable/tensors.html#torch.Tensor.to\n",
    "\n",
    "        # sequence length\n",
    "        # size of input (10 or 1)\n",
    "        sequence_length = input.size()[0]\n",
    "\n",
    "        # Run the LSTM\n",
    "\n",
    "        #########\n",
    "        ###  is this setting a new lstm each time - no\n",
    "        ######## but check how to pass hidden states\n",
    "        #########\n",
    "\n",
    "        # output - sequence of all the hidden states\n",
    "        # hidden - most recent hidden state\n",
    "        # input dimensions: [sequence_length, batch_size, 128]\n",
    "        output, self.hidden = self.lstm(input.to(\"cuda:0\").float(), self.hidden) #0].to(\"cuda:0\").float(), hidden[1].to(\"cuda:0\").float()))\n",
    "        # output dimensions: [sequence_length, batch_size, 128]\n",
    "        # outputs as many beats (sequence_length) as there were beats in the input\n",
    "        # hidden: last hidden states from last beat\n",
    "\n",
    "        # Get the output\n",
    "        output_1 = output.to('cpu') # [-5:,:,:]  # don't just take last 5\n",
    "        # take out this line after finish LSTM (other than reshaping) - unsqueeze to get right reshaping\n",
    "\n",
    "\n",
    "        #########################\n",
    "        # attention starts here #\n",
    "        #########################\n",
    "        \n",
    "        # output without attention\n",
    "        new_output = output_1.view(sequence_length, batch_size, 1, 128)  # reshape\n",
    "        avg_output = torch.sum(new_output, 2)  # return this for base LSTM (w/o attention)\n",
    "        \n",
    "        #this variable holds the output after the attention has been applied.\n",
    "        seqs = []\n",
    "\n",
    "        # generate one step at a time from the previous 5 steps, hidden state, and cell state\n",
    "        # generate x_t from hidden state, cell state from x_(t-1), inputs {x_(t-1)...(t-5)} --> get hidden state, cell state, output for next\n",
    "\n",
    "        ######\n",
    "        # ADJUST to use all of the SSM up to this beat\n",
    "        ######\n",
    "        # Find the right place in the self-similarity matrix.\n",
    "        index = input.shape[0]\n",
    "        weights = self.softmax(ssm[range(index, ssm.shape[0], ssm.shape[1]), :index])  # check SSM shape???\n",
    "\n",
    "        #this is the sparsemaxed SSM multiplied by the entire previous sequence\n",
    "        # replace .T - see which dimensions we're switching\n",
    "        weighted = (input.T*weights).T\n",
    "        #then it's summed to provide weights for each note.\n",
    "        weight_vec = (torch.sum(weighted, axis=0))\n",
    "        #This concatenates the weights for each note with the output for that note, which is then run through the linear layer to get the final output.\n",
    "        pt2 = torch.hstack((weight_vec.unsqueeze(1), avg_output[0,:,:].unsqueeze(1))).transpose(1,2)\n",
    "        attentioned = self.attention(pt2.float().to(\"cuda:0\")).to('cpu').permute(2,0,1)\n",
    "\n",
    "        # final added new output to seqs.\n",
    "        seqs.append(attentioned)\n",
    "\n",
    "        # seqs is combined into one tensor and returned, along with the hidden and cell states.\n",
    "        newoutput = torch.vstack(seqs)\n",
    "\n",
    "        return newoutput.double(), self.hidden  # hidden = hidden_state, cell_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJ0UrEmslTP-"
   },
   "source": [
    "## For Training the Model and Generating Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "rHgQoF4-Usqv"
   },
   "outputs": [],
   "source": [
    "class model_trainer():\n",
    "  def __init__(self, generator, optimizer, data, hidden_size=128, batch_size=50):\n",
    "    self.generator = generator\n",
    "    self.optimizer = optimizer\n",
    "    self.batch_size = batch_size  # play with this\n",
    "    self.hidden_size = hidden_size  # 128\n",
    "    self.data = data\n",
    "    self.data_length = 800\n",
    "\n",
    "  def train_epochs(self, num_epochs=50, full_training=False):\n",
    "    #trains each epoch\n",
    "    losslist = []\n",
    "    #useful when you want to see the progression of the SSM over time\n",
    "    piclist = []\n",
    "\n",
    "    for iter in tqdm(range(0, num_epochs)):\n",
    "      # start training the generator\n",
    "      generator.train()\n",
    "      # for each epoch, zero the gradients\n",
    "      self.generator.zero_grad()  # was optimizer\n",
    "\n",
    "\n",
    "      if full_training:\n",
    "        # use all data\n",
    "        batches = make_batches(self.batch_size, data)\n",
    "      else:\n",
    "        # use first 100 pieces\n",
    "        # can we overfit on a small dataset? if so, cna be a good thing b/c shows the model can learn\n",
    "        batches = make_batches(self.batch_size, data[:100])\n",
    "\n",
    "      cum_loss = 0\n",
    "      for batch in batches:\n",
    "        if full_training:\n",
    "          # train on full-length pieces\n",
    "          loss = self.train(batch)\n",
    "        else:\n",
    "          # train on first 105 beats of each piece\n",
    "          loss = self.train(batch[:,:105,:])  # [batch, beats, 128]\n",
    "        cum_loss+=loss\n",
    "        del loss\n",
    "      del batches\n",
    "\n",
    "      # generate example piece for piclist\n",
    "      snap = self.generate_n_examples(n=1, length=95, starter_notes=10)\n",
    "\n",
    "      losslist.append(cum_loss) \n",
    "      piclist.append(snap)\n",
    "      del snap\n",
    "\n",
    "      # after each epoch,\n",
    "      # run w/ validation\n",
    "      # if devset (validation) loss goes up for ~5 epochs in a row, early stopping\n",
    "    return losslist, piclist\n",
    "\n",
    "  #one round of training\n",
    "  def train(self, batch):\n",
    "    #seed vectors for the beginning:\n",
    "    self_sim = batch_SSM(batch.transpose(0,1), self.batch_size)\n",
    "    sequence = batch[:,0:10,:].transpose(0,1)  # start w/ some amount of the piece - 10 might be a bit much\n",
    "    generated = batch[:,0:10,:].transpose(0,1)\n",
    "\n",
    "    # reset hidden to zeros for each batch\n",
    "    generator.hidden = generator.init_hidden(self.batch_size)\n",
    "\n",
    "    # for accumulating loss\n",
    "    loss = 0\n",
    "\n",
    "    # first .forward on sequence of 10\n",
    "    # then loop from there to generate one more element\n",
    "    next_element = sequence\n",
    "    print(sequence.shape)\n",
    "\n",
    "    # take\n",
    "    for i in range(0,batch.shape[1]-10):  # for each beat\n",
    "      # iterate through beats 10-400, generating for each piece in the batch as you go\n",
    "      val = torch.rand(1)  # probability it uses original - teacher forcing\n",
    "\n",
    "      # teacher forcing - 20% of the time, don't generate, use original from piece instead\n",
    "      if (val > .8):\n",
    "        next_element = batch[:,i+1,:].unsqueeze(0)  # [1, 0/deleted, 128] to [1, 1, 128]\n",
    "      else:  # 80% of the time it adds the output\n",
    "        output, hidden = self.generator.forward(next_element, hidden, self.batch_size, self_sim)  # should take next_element\n",
    "        # take last output for each batch\n",
    "        next_element = topk_batch_sample(output, 1)\n",
    "      \n",
    "      sequence = torch.vstack((sequence, next_element.to(\"cpu\"))) # .unsqueeze(0)\n",
    "      generated = torch.vstack((generated, output))  # used for loss\n",
    "      del output\n",
    "\n",
    "    \n",
    "    # run loss after training on whole length of the pieces in the batches\n",
    "    single_loss = custom_loss(generated[10:,:,:], batch.transpose(0,1)[10:,:,:])\n",
    "    single_loss.backward()\n",
    "\n",
    "    # update the parameters of the LSTM after running on full batch\n",
    "    self.optimizer.step()\n",
    "\n",
    "    # maybe move zero_grad() here\n",
    "    loss += single_loss.detach().to('cpu')\n",
    "    del next_element\n",
    "    del self_sim\n",
    "    del sequence\n",
    "    del generated\n",
    "    del hidden\n",
    "    return (loss)\n",
    "\n",
    "  def generate_n_pieces(self, initial_vectors, n_pieces, length, batched_ssm):\n",
    "    #generates a new piece of music\n",
    "    # createnew hidden layer\n",
    "    hidden = (torch.randn(1, 1, self.hidden_size)).float()\n",
    "    hidden = (hidden, hidden)\n",
    "\n",
    "    # freeze generator so it doesn't train anymore\n",
    "    self.generator.eval()  \n",
    "  \n",
    "    # initial vectors in format [batch_size, num_notes=10, 128]\n",
    "    # change sequence to [10, batch_size, 128]\n",
    "    sequence = initial_vectors.transpose(0,1)\n",
    "    \n",
    "    # generate [length] more beats for the piece\n",
    "    for i in range(0, length):  # one at a time\n",
    "      with torch.no_grad():\n",
    "        # use n_pieces to generate as the batch size\n",
    "        output, hidden = self.generator.forward(sequence.float(), hidden, n_pieces, batched_ssm)\n",
    "        next_element = topk_batch_sample(output, 1)\n",
    "      # add element to sequence\n",
    "      sequence = torch.vstack((sequence, next_element.to(\"cpu\")))\n",
    "\n",
    "    # return sequence of beats\n",
    "    return sequence\n",
    "  \n",
    "  def generate_n_examples(self, n=1, length=390, starter_notes=10, source_piece=0):\n",
    "    # get piece from the data\n",
    "    piece = self.data[source_piece][0].unsqueeze(0)  # in format [1, 400, 128]\n",
    "\n",
    "    # take first 10 notes in format [1, 10, 128]\n",
    "    first_vec = piece[:,0:starter_notes,:]\n",
    "\n",
    "    # create batched SSMs for each piece\n",
    "    batched_ssms = batch_SSM(piece.transpose(0,1), n)\n",
    "\n",
    "    # generate pieces\n",
    "    new_gen = self.generate_n_pieces(first_vec, n, length, batched_ssms)\n",
    "\n",
    "    # clean up variables\n",
    "    del piece\n",
    "    del first_vec\n",
    "    del batched_ssms\n",
    "\n",
    "    # return pieces\n",
    "    return new_gen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PJkbSoPlQV0"
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QghsXxPCngY8"
   },
   "outputs": [],
   "source": [
    "#this function takes in the piece of music and returns the chroma vectors\n",
    "def get_chroma(roll, length):\n",
    "    chroma_matrix = torch.zeros((roll.size()[0],12))\n",
    "    for note in range(0, 12):\n",
    "        chroma_matrix[:, note] = torch.sum(roll[:, note::12], axis=1)\n",
    "    return chroma_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kbVFABahqRyr"
   },
   "outputs": [],
   "source": [
    "#this takes in the sequence and creates a self-similarity matrix (it calls chroma function inside)\n",
    "def SSM(sequence):\n",
    "  #tensor will be in form length, hidden_size (128)\n",
    "  cos = nn.CosineSimilarity(dim=1)\n",
    "  chrom = get_chroma(sequence, sequence.size()[0])\n",
    "  len = chrom.size()[0]\n",
    "  SSM=torch.zeros((len, len))\n",
    "  for i in range(0, len):\n",
    "    SSM[i] = cos(chrom[i].view(1, -1),chrom)\n",
    "  return (SSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TL98RMlOPkFA"
   },
   "outputs": [],
   "source": [
    "#this bundles the SSM function.\n",
    "def batch_SSM(seq, batch_size):\n",
    "  # takes sequence in format\n",
    "  # [beats=400, batch_size, 128]\n",
    "  # print(\"SSM\\tsequence_shape\", seq.shape)\n",
    "  SSMs = []\n",
    "  for i in range(0, batch_size):\n",
    "    # print(\"SSM\\tsequence\", seq[:,i,:].shape)\n",
    "    ssm = SSM(seq[:,i,:])  # [beats, batch, 128]\n",
    "    # print(\"SSM\\tssm\", ssm.shape)\n",
    "    SSMs.append(ssm)  \n",
    "  return torch.vstack(SSMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zWRL4AHyhqJo"
   },
   "outputs": [],
   "source": [
    "#Takes in the batch size and data and returns batches of the batch size\n",
    "def make_batches(batch_size, data):\n",
    "  random.shuffle(data)\n",
    "  batches = []\n",
    "  num_batches = len(data)//batch_size\n",
    "  for i in range(0, num_batches):\n",
    "    batch = torch.cat(list(np.array(data)[i*batch_size: (i+1)*(batch_size)][:, 0])).view(batch_size, target_size, 128)\n",
    "    batches.append(batch)\n",
    "  return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "w0luDdramUyB"
   },
   "outputs": [],
   "source": [
    "#sampling function \n",
    "def topk_sample_one(sequence, k):\n",
    "  #takes in size sequence length, batch size, values\n",
    "  softmax = sparsemax.Sparsemax(dim=2)\n",
    "  vals, indices = torch.topk(sequence[:, :, 20:108],k)\n",
    "  indices+=20\n",
    "  seq = torch.distributions.Categorical(softmax(vals.float()))\n",
    "  samples = seq.sample()\n",
    "  onehot = F.one_hot(torch.gather(indices, -1, samples.unsqueeze(-1)), num_classes = sequence.shape[2]).squeeze(dim=2)\n",
    "  return(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "86DYqbCtrpqs"
   },
   "outputs": [],
   "source": [
    "#samples multiple times for the time-step\n",
    "def topk_batch_sample(sequence, k):\n",
    "  for i in range(0, 3):\n",
    "    new= topk_sample_one(sequence, k)\n",
    "    if i ==0:\n",
    "      sum = new\n",
    "    else:\n",
    "      sum+=new\n",
    "  return(torch.where(sum>0, 1, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "hX5cldo5GTM0"
   },
   "outputs": [],
   "source": [
    "def custom_loss(output, target):\n",
    "  #custom loss function\n",
    "  criterion = nn.BCEWithLogitsLoss()\n",
    "  weighted_mse = criterion(output.double(), target.double())\n",
    "  batch_size = output.size()[1]\n",
    "  ssm_err = 0\n",
    "  for i in range(0, batch_size):\n",
    "    SSM1 = SSM(output[:,i,:])\n",
    "    SSM2 = SSM(target[:,i, :])\n",
    "    ssm_err += (torch.sum((SSM1-SSM2)**2)/(SSM2.size(0)**2))\n",
    "\n",
    "\n",
    "  return torch.sum(weighted_mse)+ssm_err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7OjWY1ubk1PX"
   },
   "source": [
    "## Train Model Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1ie7zGkh0sO",
    "outputId": "3f292367-8a74-4a8a-9300-1ab06b547ecb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa7d0f7cc90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data; in these small-scale tests I usually loaded the val data because it didn't take as long to load. When you are training, load the train data.\n",
    "data = torch.load(my_drive_path + \"usable_data/train_tempo_800.csv\")  # make train for real training\n",
    "# val = torch.load(my_drive_path + \"usable_data/validation_tempo.csv\")\n",
    "torch.manual_seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "xUfiEEqwqrjQ"
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4cb7bfed47ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# create model and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmusic_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/csc294/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m/opt/anaconda3/envs/csc294/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/csc294/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# Resets _flat_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/csc294/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/csc294/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    983\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    984\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/csc294/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# create model and optimizer\n",
    "generator = music_generator(128,128).to(\"cuda:0\")\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=0.005)\n",
    "\n",
    "# parameters\n",
    "hidden_size = 128  # maybe don't touch?\n",
    "batch_size = 25    # play with this\n",
    "target_size = 800  # make this not global?\n",
    "\n",
    "# model trainer\n",
    "trainer = model_trainer(generator, optimizer, data, hidden_size, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-d_UFqxe0HGE",
    "outputId": "5aa32c21-59e3-44d2-badf-c01c6880303b"
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "losslist, piclist = trainer.train_epochs(num_epochs=3, full_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p4KywdaS-83b"
   },
   "outputs": [],
   "source": [
    "#this code can save a model if you need it\n",
    "#!touch my_drive_path+\"model.txt\"\n",
    "#torch.save(generator, my_drive_path + \"model.txt\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efPcLZTbk-Zz"
   },
   "source": [
    "## View Results and Generate Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HcKawGKyoY-"
   },
   "outputs": [],
   "source": [
    "# view snapshots of pieces at each epoch\n",
    "plt.imshow(SSM(piclist[-1].squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dr0lTbeGSPW2"
   },
   "outputs": [],
   "source": [
    "# show loss at each epoch\n",
    "plt.scatter(range(0,len(losslist)), losslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJSNH2jRPw0V"
   },
   "outputs": [],
   "source": [
    "# create example\n",
    "index = 0  # which source piece\n",
    "new_gen = trainer.generate_n_examples(n=1, length=390, starter_notes=10, source_piece=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hxhjd4ijzH6-"
   },
   "outputs": [],
   "source": [
    "# show SSM for first piece\n",
    "plt.imshow(SSM(data[index][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBBYEaOAPHj_"
   },
   "outputs": [],
   "source": [
    "# show SSM for new piece\n",
    "plt.imshow(SSM(new_gen.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "luEz48jIyY1U"
   },
   "outputs": [],
   "source": [
    "# show new piece\n",
    "plt.imshow(new_gen.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1Rz8WF2lE5G"
   },
   "source": [
    "## Save Example Sequence to Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5jemNprz1mB2"
   },
   "outputs": [],
   "source": [
    "#this code translates the generated sequence to audio\n",
    "def stop_note(note, time):\n",
    "    return Message('note_off', note = note,\n",
    "                   velocity = 0, time = time)\n",
    "\n",
    "def start_note(note, time):\n",
    "    return Message('note_on', note = note,\n",
    "                   velocity = 120, time = time)\n",
    "\n",
    "def roll_to_track(roll, tempo):\n",
    "    delta = 0\n",
    "\n",
    "    \n",
    "    # MIDI note for first column.\n",
    "    midi_base = 0\n",
    "    notes = [0] * len(roll[0])\n",
    "    for row in roll:\n",
    "        for i, col in enumerate(row):\n",
    "            note = i\n",
    "            if col>notes[i] and col!=0: \n",
    "                if notes[i]!=0:\n",
    "                    yield stop_note(note, delta)\n",
    "                    delta = 0\n",
    "                yield start_note(i, delta)\n",
    "                delta = 0\n",
    "                notes[i] = note\n",
    "            elif col == 0:\n",
    "                if notes[i]!=0:\n",
    "                    # Stop the ringing note\n",
    "                    yield stop_note(note, delta)\n",
    "                    delta = 0\n",
    "                notes[i] = 0\n",
    "        # ms per row\n",
    "        delta += int(np.round((1/(tempo/60))*1000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hMlI54ma1nUt"
   },
   "outputs": [],
   "source": [
    "new_roll_final = np.vstack((new_gen.squeeze(), np.zeros(128)))\n",
    "midi = MidiFile(type = 1)\n",
    "midi.tracks.append(MidiTrack(roll_to_track(new_roll_final, data[index][1])))\n",
    "midi.save(my_drive_path + 'audio_outputs/blank.midi')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

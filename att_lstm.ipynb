{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UhjTVBAwtYJd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pretty_midi\n",
    "from mido import Message, MidiFile, MidiTrack\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import torch.distributions\n",
    "import sparsemax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 716,
     "status": "ok",
     "timestamp": 1639599226660,
     "user": {
      "displayName": "Sophia Hager",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "07903191433304959107"
     },
     "user_tz": 300
    },
    "id": "f1ie7zGkh0sO",
    "outputId": "abee0024-3779-4edb-a0f8-cd9ccccc1715"
   },
   "outputs": [],
   "source": [
    "data = torch.load(\"train_tempo.csv\")\n",
    "torch.manual_seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QghsXxPCngY8"
   },
   "outputs": [],
   "source": [
    "def get_chroma(roll, length):\n",
    "    chroma_matrix = torch.zeros((roll.size()[0],12))\n",
    "    for note in range(0, 12):\n",
    "        chroma_matrix[:, note] = torch.sum(roll[:, note::12], axis=1)\n",
    "    return chroma_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TL98RMlOPkFA"
   },
   "outputs": [],
   "source": [
    "def batch_SSM(seq, batch_size):\n",
    "  SSMs = []\n",
    "  for i in range(0, batch_size):\n",
    "    SSMs.append(SSM(seq[:,i, :]))\n",
    "  return torch.vstack(SSMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbVFABahqRyr"
   },
   "outputs": [],
   "source": [
    "def SSM(sequence):\n",
    "  #tensor will be in form length, hidden_size (128)\n",
    "  cos = nn.CosineSimilarity(dim=1)\n",
    "  chrom = get_chroma(sequence, sequence.size()[0])\n",
    "  len = chrom.size()[0]\n",
    "  SSM=torch.zeros((len, len))\n",
    "  for i in range(0, len):\n",
    "    SSM[i] = cos(chrom[i].view(1, -1),chrom)\n",
    "  return (SSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eoVsvEBOMtbe"
   },
   "outputs": [],
   "source": [
    "def threshold_SSM(ssm):\n",
    "  return torch.where(ssm>.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWRL4AHyhqJo"
   },
   "outputs": [],
   "source": [
    "def make_batches(batch_size, data):\n",
    "  random.shuffle(data)\n",
    "  batches = []\n",
    "  num_batches = len(data)//batch_size\n",
    "  for i in range(0, num_batches):\n",
    "    batch = torch.cat(list(np.array(data)[i*batch_size: (i+1)*(batch_size)][:, 0])).view(batch_size, 400, 128)\n",
    "    batches.append(batch)\n",
    "  return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iuKD5iNkyChL"
   },
   "outputs": [],
   "source": [
    "class music_generator(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(output_size, hidden_size, num_layers=1, bidirectional=True)\n",
    "        self.attention = nn.Linear(2, 1)\n",
    "        self.softmax = sparsemax.Sparsemax(dim=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, input, hidden, batch, sequence_length, ssm):\n",
    "        output, hidden = self.lstm(input.to(\"cuda:0\").float(), (hidden[0].to(\"cuda:0\").float(), hidden[1].to(\"cuda:0\").float()))\n",
    "        output_1 = output.to('cpu')[-5:, :,:]\n",
    "        new_output = output_1.view(5, batch, 2, 128)\n",
    "        sum_output = torch.sum(new_output, 2)\n",
    "        hidden_1_0 = hidden[0].to('cpu')\n",
    "        hidden_1_1= hidden[1].to('cpu')\n",
    "\n",
    "        \n",
    "\n",
    "        seqs = []\n",
    "        for l in range(0,5):\n",
    "          index = input.shape[0]+l\n",
    "          weights = self.softmax(ssm[range(index, ssm.shape[0], ssm.shape[1]), :index])\n",
    "          if l!=0:\n",
    "            input_and_gen = torch.vstack((input[:,:,:], torch.vstack((seqs))))\n",
    "          else:\n",
    "            input_and_gen = input[:,:,:]\n",
    "          weighted = (input_and_gen.T*weights).T\n",
    "          weight_vec = (torch.sum(weighted, axis=0))\n",
    "          pt2 = torch.hstack((weight_vec.unsqueeze(1), sum_output[l, : ,:].unsqueeze(1))).transpose(1,2)\n",
    "          attentioned = self.attention(pt2.float().to(\"cuda:0\")).to('cpu').permute(2,0,1)\n",
    "          seqs.append(attentioned)\n",
    "        newoutput = torch.vstack(seqs)\n",
    "\n",
    "        del output\n",
    "        del output_1\n",
    "        del ssm\n",
    "        del weights\n",
    "        del seqs\n",
    "        del hidden\n",
    "        del pt2\n",
    "        del attentioned\n",
    "        del input\n",
    "\n",
    "\n",
    "        return newoutput.double(), (hidden_1_0,hidden_1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3G0ubkSHzlO"
   },
   "outputs": [],
   "source": [
    "def topk_sample_one(sequence, k):\n",
    "  #takes in size sequence length, batch size, values\n",
    "  softmax = sparsemax.Sparsemax(dim=2)\n",
    "  vals, indices = torch.topk(sequence[:, :, 20:108],k)\n",
    "  indices+=20\n",
    "  seq = torch.distributions.Categorical(softmax(vals.float()))\n",
    "  samples = seq.sample()\n",
    "  onehot = F.one_hot(torch.gather(indices, -1, samples.unsqueeze(-1)), num_classes = sequence.shape[2]).squeeze(dim=2)\n",
    "  return(onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tS9oiFbGHzlO"
   },
   "outputs": [],
   "source": [
    "def topk_batch_sample(sequence, k):\n",
    "  for i in range(0, 3):\n",
    "    new= topk_sample_one(sequence, k)\n",
    "    if i ==0:\n",
    "      sum = new\n",
    "    else:\n",
    "      sum+=new\n",
    "  return(torch.where(sum>0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iena_9fsbBic"
   },
   "outputs": [],
   "source": [
    "def train(generator, piece, optimizer, batch_size, hidden_size):\n",
    "  self_sim = batch_SSM(piece.transpose(0,1), batch_size)\n",
    "  sequence = piece[:,0:10].transpose(0,1)\n",
    "  generated = piece[:,0:10].transpose(0,1)\n",
    "  hidden = (torch.randn(2, batch_size, hidden_size))\n",
    "  hidden = (hidden, hidden)\n",
    "  loss= 0\n",
    "  for i in range(0,piece.shape[1]-10, 5):\n",
    "    val = torch.rand(1)\n",
    "    seq_length = sequence.size()[0]\n",
    "    optimizer.zero_grad()\n",
    "    output, hidden = generator.forward(sequence, hidden, batch_size, seq_length, self_sim)\n",
    "    if (val<.8):\n",
    "      next_element = topk_batch_sample(output, 5)\n",
    "    else:\n",
    "      next_element = piece[:,i+1:i+6].transpose(0,1)\n",
    "      \n",
    "    sequence = torch.vstack((sequence, next_element.to(\"cpu\")))\n",
    "    generated = torch.vstack((generated, output))\n",
    "    del next_element\n",
    "    del output\n",
    "  single_loss = custom_loss(generated[1:, :, :], piece.transpose(0,1)[1:,:,:])\n",
    "  single_loss.backward()\n",
    "\n",
    "\n",
    "  optimizer.step()\n",
    "  loss +=single_loss.detach().to('cpu')\n",
    "  del self_sim\n",
    "  del sequence\n",
    "  del generated\n",
    "  del hidden\n",
    "  del optimizer\n",
    "  del generator\n",
    "  return (loss/(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8uO1iCCWWcra"
   },
   "outputs": [],
   "source": [
    "def train_epochs(num_epochs, generator, optimizer, batch_size, hidden_size, data):\n",
    "  losslist = []\n",
    "  piclist = []\n",
    "  for iteration in tqdm(range(0, num_epochs)):\n",
    "    generator.train()\n",
    "    batches = make_batches(batch_size, data)\n",
    "    cum_loss= 0\n",
    "    for batch in batches:\n",
    "      thing =train(generator, batch, optimizer, batch_size , hidden_size)\n",
    "      cum_loss+=thing\n",
    "      del thing\n",
    "    del batches\n",
    "    first_vec = data[0][0].unsqueeze(0)[:,0:5,:]\n",
    "    snap = generate(generator, first_vec, 1, 95, 128, batch_SSM(data[0][0].unsqueeze(0).transpose(0,1)[:, :,:], 1))\n",
    "\n",
    "    losslist.append(cum_loss) \n",
    "    piclist.append(snap)\n",
    "    del snap\n",
    "    del first_vec\n",
    "    \n",
    "    pathname = (\"trained/epoch-\"+str(iteration)+\"-loss-\"+str(cum_loss.item())[:7]+\".txt\")\n",
    "    f = open(pathname, \"x\")\n",
    "    torch.save(generator, pathname )\n",
    "    f.close()\n",
    "    \n",
    "  return losslist, piclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dOFR2z-30Cmb"
   },
   "outputs": [],
   "source": [
    "def generate(generator, initial_vectors, batch_size, length , hidden_shape, batched_ssm):\n",
    "  hidden = (torch.randn(2, 1, hidden_shape)).float()\n",
    "  generator.eval()\n",
    "  sequence = initial_vectors.transpose(0,1)\n",
    "  hidden = (hidden, hidden)\n",
    "  for i in range(0, length,5):\n",
    "    seq_length = sequence.size()[0]\n",
    "    with torch.no_grad():\n",
    "      output, hidden = generator.forward(sequence.float(), hidden, batch_size, seq_length, batched_ssm)\n",
    "      next_element = topk_batch_sample(output[-5:, :,:], 5)\n",
    "    sequence = torch.vstack((sequence, next_element.to(\"cpu\")))\n",
    "  return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hX5cldo5GTM0"
   },
   "outputs": [],
   "source": [
    "def custom_loss(output, target):\n",
    "  criterion = nn.BCEWithLogitsLoss()\n",
    "  weighted_mse = criterion(output.double(), target.double())\n",
    "  batch_size = output.size()[1]\n",
    "  ssm_err = 0\n",
    "  for i in range(0, batch_size):\n",
    "    SSM1 = SSM(output[:,i,:])\n",
    "    SSM2 = SSM(target[:,i, :])\n",
    "    ssm_err += (torch.sum((SSM1-SSM2)**2)/(SSM2.size(0)**2))\n",
    "\n",
    "\n",
    "  return torch.sum(weighted_mse)+ssm_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xUfiEEqwqrjQ"
   },
   "outputs": [],
   "source": [
    "generator = music_generator(128,128).to(\"cuda:0\")\n",
    "optimizer = torch.optim.Adam(generator.parameters(), lr=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-d_UFqxe0HGE",
    "outputId": "783deafa-e05d-44c2-e9ea-97e1501658bc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "losslist, piclist = train_epochs(30, generator, optimizer, 50, 128, data)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "att_lstm.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
